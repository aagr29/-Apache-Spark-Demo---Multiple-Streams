{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "from kafka import KafkaProducer\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import timezone,datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from tutorial\n",
    "def publish_message(producer_instance, topic_name, value):\n",
    "    try:\n",
    "        producer_instance.send(topic_name, value=value)\n",
    "#         producer_instance.flush()\n",
    "#         print('Message published successfully. Data: ' + str(value))\n",
    "    except Exception as ex:\n",
    "        print('Exception in publishing message.')\n",
    "        print(str(ex))\n",
    "        \n",
    "def connect_kafka_producer():\n",
    "    _producer = None\n",
    "    try:\n",
    "        _producer = KafkaProducer(bootstrap_servers=['localhost:9092'],\n",
    "                                  value_serializer=lambda x: dumps(x).encode('ascii'),\n",
    "                                  api_version=(0, 10))\n",
    "    except Exception as ex:\n",
    "        print('Exception while connecting Kafka.')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return _producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to send an attack per machine using dictionary to keep track of indexes\n",
    "def send_attack_per_machine(df_machine,start_index_dict,end_index_dict):\n",
    "    #Which machine to send rows from\n",
    "    key = df_machine.machine[0]\n",
    "    #Should number of rows sent for each rows be random or does the randomness comes a step earlier?\n",
    "    rowsToSend = random.randrange(100,500)\n",
    "    #Size of the given df\n",
    "    totalRows = int(df_machine.shape[0])\n",
    "#     print('Machine No: %d'%key)\n",
    "#     print('Rows to send: %d'%(rowsToSend))\n",
    "    #Add to the end index of the selected machine \n",
    "    end_index_dict[key] = end_index_dict[key]+rowsToSend\n",
    "    #Get the start index of the machine from previous run\n",
    "    start_index = start_index_dict[key]\n",
    "    #Get end index from previous run\n",
    "    end_index = end_index_dict[key]\n",
    "    #Check whether end index is lesser than total number of rows in df\n",
    "    if(end_index>totalRows):\n",
    "#         print('second')\n",
    "        #Set start_index of the particular machine to 0 in the dict\n",
    "        start_index_dict[key] = 0\n",
    "        #Get the start_index which is now 0\n",
    "        start_index = start_index_dict[key]\n",
    "        #update the end_index for the particular machine to rowsToSend in the dictt\n",
    "        end_index_dict[key] = rowsToSend\n",
    "        #get the end index\n",
    "        end_index = end_index_dict[key]\n",
    "#         print('end index: %d'%(end_index))\n",
    "#         print('start index: %d'%(start_index))\n",
    "        #Create a temp df with the selected rows to be sent\n",
    "    temp = df_machine.iloc[start_index:end_index,:]\n",
    "    #appened the ts in unix-timestamp\n",
    "    temp['ts'] = int(datetime.now().replace(tzinfo=timezone.utc).timestamp())\n",
    "    #publish the message to kafka stream\n",
    "    publish_message(producer, topic, temp.to_dict(orient='record'))\n",
    "    #update the start_index to end_index\n",
    "    start_index_dict[key] = end_index\n",
    "#     print('start_index_dict :%s'%(str(start_index_dict)))\n",
    "#     print('end_index_dict :%s'%(str(end_index_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index_dict = {4:0, 5:0, 6:0, 7:0, 8:0}\n",
    "end_index_dict = {4:0, 5:0, 6:1, 7:0, 8:0}\n",
    "producer = connect_kafka_producer()\n",
    "topic = 'Assignment2B-process'\n",
    "df_process = pd.read_csv('Streaming_Linux_process.csv')\n",
    "df_machine_4 = df_process.loc[df_process['machine']==4].reset_index()\n",
    "df_machine_5 = df_process.loc[df_process['machine']==5].reset_index()\n",
    "df_machine_6 = df_process.loc[df_process['machine']==6].reset_index()\n",
    "df_machine_7 = df_process.loc[df_process['machine']==7].reset_index()\n",
    "df_machine_8 = df_process.loc[df_process['machine']==8].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process.groupby('machine').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    send_attack_per_machine(df_machine_4,start_index_dict,end_index_dict)\n",
    "    send_attack_per_machine(df_machine_5,start_index_dict,end_index_dict)\n",
    "    send_attack_per_machine(df_machine_6,start_index_dict,end_index_dict)\n",
    "    send_attack_per_machine(df_machine_7,start_index_dict,end_index_dict)\n",
    "    send_attack_per_machine(df_machine_8,start_index_dict,end_index_dict)\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
